{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malware Opcode Classification, Minimum Samples for 95% accuracy\n",
    "\n",
    "Authored by David Luong and Albert Giang\n",
    "\n",
    "LSTM Reference: https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "\n",
    "The Notebook contains both machine learning and deep learning classifiers. The main function calls on each of the classifiers and perform a hybrid of binary search and jump search to find the minimum samples needed for 95% accuracy\n",
    "This Notebook deals with the Dense and CNN VAE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt # for plotting model loss\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "#Import svm model\n",
    "from sklearn import svm\n",
    "#Import random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "#Import knn model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Final evaluation of the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(7)\n",
    "np.random.seed(7)\n",
    "tf.keras.utils.set_random_seed(7)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# Assign main directory to a variable\n",
    "main_dir=os.path.dirname(sys.path[0])\n",
    "\n",
    "import data\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(X, y, real_malware, target_names,max_sequence_length, embedding_vector_length, num_unique):\n",
    "    classifier_name = 'LSTM'\n",
    "    #print('******%s******' % classifier_name)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "    clf = Sequential()\n",
    "    clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "    clf.add(LSTM(100))\n",
    "    clf.add(Dense(1, activation='sigmoid'))\n",
    "    clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])   \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "    clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "    scores = clf.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy = scores[1]\n",
    "    y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall= recall_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    #class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "    return accuracy, precision, recall\n",
    "\n",
    "def lstm_kfold(X, y, real_malware, target_names,max_sequence_length, embedding_vector_length, num_unique):\n",
    "    classifier_name = 'LSTM'\n",
    "    #print('******%s******' % classifier_name)\n",
    "    k = 5\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    best = 0.\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=18245)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "    \n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # build LSTM model\n",
    "        clf = Sequential()\n",
    "        clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "        clf.add(LSTM(100))\n",
    "        clf.add(Dense(1, activation='sigmoid'))\n",
    "        clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])   \n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "        clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "        scores = clf.evaluate(X_test, y_test, verbose=0)\n",
    "        acc = scores[1]\n",
    "        accuracy.append(acc)\n",
    "        if acc>best:\n",
    "            best = acc\n",
    "            best_train, best_test = train_index, test_index\n",
    "            \n",
    "        y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        \n",
    "    # print('\\n%s accuracy: ' % classifier_name, accuracy)\n",
    "    # print('%s precision: ' % classifier_name, precision)\n",
    "    # print('%s recall: ' % classifier_name, recall)\n",
    "    \n",
    "    # print('\\nAvg %s accuracy: %0.2f'% (classifier_name, np.mean(np.array(accuracy))))\n",
    "    # print('Avg %s precision: %0.2f'% (classifier_name, np.mean(np.array(precision))))\n",
    "    # print('Avg %s recall: %0.2f\\n'% (classifier_name ,np.mean(np.array(recall))))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[best_train], X[best_test], y[best_train], y[best_test]\n",
    "    clf = Sequential()\n",
    "    clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "    clf.add(LSTM(100))\n",
    "    clf.add(Dense(1, activation='sigmoid'))\n",
    "    clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])   \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "    clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "    y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    #class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "\n",
    "    return np.mean(np.array(accuracy)), np.mean(np.array(precision)), np.mean(np.array(recall))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Bidirectional LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_lstm(X, y, real_malware, target_names,max_sequence_length, embedding_vector_length, num_unique):\n",
    "    classifier_name = 'Bidirectional_LSTM'\n",
    "    #print('******%s******' % classifier_name)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "    clf = Sequential()\n",
    "    clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "    #clf.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "    clf.add(Bidirectional(LSTM(100, dropout=0.2)))\n",
    "    clf.add(Dense(1, activation='sigmoid'))\n",
    "    clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "    clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "    scores = clf.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy = scores[1]\n",
    "    y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall= recall_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    #class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "def bi_lstm_kfold(X, y, real_malware, target_names,max_sequence_length, embedding_vector_length, num_unique):\n",
    "    classifier_name = 'Bidirectional_LSTM'\n",
    "    #print('******%s******' % classifier_name)\n",
    "    k = 5\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    best = 0.\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=18245)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "    \n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # build LSTM model\n",
    "        clf = Sequential()\n",
    "        clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "        #clf.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "        clf.add(Bidirectional(LSTM(100, dropout=0.2)))\n",
    "        clf.add(Dense(1, activation='sigmoid'))\n",
    "        clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "        clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "        scores = clf.evaluate(X_test, y_test, verbose=0)\n",
    "        acc = scores[1]\n",
    "        accuracy.append(acc)\n",
    "        if acc>best:\n",
    "            best = acc\n",
    "            best_train, best_test = train_index, test_index\n",
    "            \n",
    "        y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        \n",
    "    # print('\\n%s accuracy: ' % classifier_name, accuracy)\n",
    "    # print('%s precision: ' % classifier_name, precision)\n",
    "    # print('%s recall: ' % classifier_name, recall)\n",
    "    \n",
    "    # print('\\nAvg %s accuracy: %0.2f'% (classifier_name, np.mean(np.array(accuracy))))\n",
    "    # print('Avg %s precision: %0.2f'% (classifier_name, np.mean(np.array(precision))))\n",
    "    # print('Avg %s recall: %0.2f\\n'% (classifier_name ,np.mean(np.array(recall))))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[best_train], X[best_test], y[best_train], y[best_test]\n",
    "    clf = Sequential()\n",
    "    clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "    #clf.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "    clf.add(Bidirectional(LSTM(100, dropout=0.2)))\n",
    "    clf.add(Dense(1, activation='sigmoid'))\n",
    "    clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "    clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "    y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    #class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "\n",
    "    return np.mean(np.array(accuracy)), np.mean(np.array(precision)), np.mean(np.array(recall))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define CNN LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_lstm(X, y, real_malware, target_names,max_sequence_length, embedding_vector_length, num_unique):\n",
    "    classifier_name = 'CNN_LSTM'\n",
    "    #print('******%s******' % classifier_name)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "    \n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "    clf = Sequential()\n",
    "    clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "    clf.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "    clf.add(MaxPooling1D(pool_size=2))\n",
    "    clf.add(LSTM(100))\n",
    "    clf.add(Dense(1, activation='sigmoid'))\n",
    "    clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "    clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "    scores = clf.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy = scores[1]\n",
    "    y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall= recall_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    #class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "def cnn_lstm_kfold(X, y, real_malware, target_names,max_sequence_length, embedding_vector_length, num_unique):\n",
    "    classifier_name = 'CNN_LSTM'\n",
    "    #print('******%s******' % classifier_name)\n",
    "    k = 5\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    best = 0.\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=18245)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "    \n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # build LSTM model\n",
    "        clf = Sequential()\n",
    "        clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "        clf.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "        clf.add(MaxPooling1D(pool_size=2))\n",
    "        clf.add(LSTM(100))\n",
    "        clf.add(Dense(1, activation='sigmoid'))\n",
    "        clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "        clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "        scores = clf.evaluate(X_test, y_test, verbose=0)\n",
    "        acc = scores[1]\n",
    "        accuracy.append(acc)\n",
    "        if acc>best:\n",
    "            best = acc\n",
    "            best_train, best_test = train_index, test_index\n",
    "            \n",
    "        y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        \n",
    "    # print('\\n%s accuracy: ' % classifier_name, accuracy)\n",
    "    # print('%s precision: ' % classifier_name, precision)\n",
    "    # print('%s recall: ' % classifier_name, recall)\n",
    "    \n",
    "    # print('\\nAvg %s accuracy: %0.2f'% (classifier_name, np.mean(np.array(accuracy))))\n",
    "    # print('Avg %s precision: %0.2f'% (classifier_name, np.mean(np.array(precision))))\n",
    "    # print('Avg %s recall: %0.2f\\n'% (classifier_name ,np.mean(np.array(recall))))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[best_train], X[best_test], y[best_train], y[best_test]\n",
    "    clf = Sequential()\n",
    "    clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "    clf.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "    clf.add(MaxPooling1D(pool_size=2))\n",
    "    clf.add(LSTM(100))\n",
    "    clf.add(Dense(1, activation='sigmoid'))\n",
    "    clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "    clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "    y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    #class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "\n",
    "    return np.mean(np.array(accuracy)), np.mean(np.array(precision)), np.mean(np.array(recall))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define SVM Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vector_machine(X, y, real_malware, target_names,max_sequence_length):\n",
    "    classifier_name = 'Support Vector Machines'\n",
    "    #print('******%s******' % classifier_name)\n",
    "    k = 5\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    best = 0.\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf = svm.SVC(C=5, kernel='rbf')\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc = clf.score(X_test, y_test)\n",
    "        accuracy.append(acc)\n",
    "        if acc>best:\n",
    "            best = acc\n",
    "            best_train, best_test = train_index, test_index\n",
    "            \n",
    "        y_pred = clf.predict(X_test)\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        \n",
    "    # print('\\n%s accuracy: ' % classifier_name, accuracy)\n",
    "    # print('%s precision: ' % classifier_name, precision)\n",
    "    # print('%s recall: ' % classifier_name, recall)\n",
    "    \n",
    "    # print('\\nAvg %s accuracy: %0.2f'% (classifier_name, np.mean(np.array(accuracy))))\n",
    "    # print('Avg %s precision: %0.2f'% (classifier_name, np.mean(np.array(precision))))\n",
    "    # print('Avg %s recall: %0.2f\\n'% (classifier_name ,np.mean(np.array(recall))))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[best_train], X[best_test], y[best_train], y[best_test]\n",
    "    clf = svm.SVC(C=5, kernel='rbf')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    #class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "\n",
    "    return np.mean(np.array(accuracy)), np.mean(np.array(precision)), np.mean(np.array(recall))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X, y, real_malware, target_names,max_sequence_length):\n",
    "    classifier_name = 'Random Forest'\n",
    "    #print('******%s******' % classifier_name)\n",
    "    k = 5\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    best = 0.\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=6357)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf = RandomForestClassifier(n_estimators=50, max_depth=5)\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc = clf.score(X_test, y_test)\n",
    "        accuracy.append(acc)\n",
    "        if acc>best:\n",
    "            best = acc\n",
    "            best_train, best_test = train_index, test_index\n",
    "            \n",
    "        y_pred = clf.predict(X_test)\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        \n",
    "    # print('\\n%s accuracy: ' % classifier_name, accuracy)\n",
    "    # print('%s precision: ' % classifier_name, precision)\n",
    "    # print('%s recall: ' % classifier_name, recall)\n",
    "    \n",
    "    # print('\\nAvg %s accuracy: %0.2f'% (classifier_name, np.mean(np.array(accuracy))))\n",
    "    # print('Avg %s precision: %0.2f'% (classifier_name, np.mean(np.array(precision))))\n",
    "    # print('Avg %s recall: %0.2f\\n'% (classifier_name ,np.mean(np.array(recall))))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[best_train], X[best_test], y[best_train], y[best_test]\n",
    "    clf = RandomForestClassifier(n_estimators=50, max_depth=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    #class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "\n",
    "    return np.mean(np.array(accuracy)), np.mean(np.array(precision)), np.mean(np.array(recall))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define k-Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbors(X, y, real_malware, target_names,max_sequence_length):\n",
    "    classifier_name = 'K-Nearest Neighbors'\n",
    "    #print('******%s******' % classifier_name)\n",
    "    k = 5\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    best = 0.\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=18245)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf = KNeighborsClassifier(n_neighbors=1, p=2)\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc = clf.score(X_test, y_test)\n",
    "        accuracy.append(acc)\n",
    "        if acc>best:\n",
    "            best = acc\n",
    "            best_train, best_test = train_index, test_index\n",
    "            \n",
    "        y_pred = clf.predict(X_test)\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        \n",
    "    # print('\\n%s accuracy: ' % classifier_name, accuracy)\n",
    "    # print('%s precision: ' % classifier_name, precision)\n",
    "    # print('%s recall: ' % classifier_name, recall)\n",
    "    \n",
    "    # print('\\nAvg %s accuracy: %0.2f'% (classifier_name, np.mean(np.array(accuracy))))\n",
    "    # print('Avg %s precision: %0.2f'% (classifier_name, np.mean(np.array(precision))))\n",
    "    # print('Avg %s recall: %0.2f\\n'% (classifier_name ,np.mean(np.array(recall))))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[best_train], X[best_test], y[best_train], y[best_test]\n",
    "    clf = KNeighborsClassifier(n_neighbors=1, p=2)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    #class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "\n",
    "    return np.mean(np.array(accuracy)), np.mean(np.array(precision)), np.mean(np.array(recall))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_search(real_malware, function, present_num_sample = 0):\n",
    "    #### Define Run Settings ####\n",
    "    tf.random.set_seed(7)\n",
    "    np.random.seed(7)\n",
    "    tf.keras.utils.set_random_seed(7)\n",
    "\n",
    "    max_sequence_length = 600\n",
    "    use_deep_classifiers = 1 # 1+ = use, 0 do not use \n",
    "    target_names = ['Real', 'Fake']\n",
    "    embedding_vector_length = 32\n",
    "    num_tries = 20\n",
    "    save_epoch = []\n",
    "    latent_dim = 100\n",
    "    architecture = 'WGANGP'\n",
    "    deep = ['cnn_lstm_kfold','bi_lstm_kfold','lstm_kfold','cnn_lstm','bi_lstm','lstm']\n",
    "\n",
    "\n",
    "    if real_malware == 'AllFiveFamilies':\n",
    "        epoch_num = 1000\n",
    "    else:\n",
    "        epoch_num = 10000\n",
    "    \n",
    "\n",
    "    #### Load Real Samples ####\n",
    "    data_obj = data.DATA(real_malware, 600)\n",
    "    real_data, num_unique = data_obj.load_data(True)\n",
    "    print('Total valid samples for %s: %i' % (real_malware, len(real_data)))\n",
    "\n",
    "    ### Load Trained WGAN-GP Model ###\n",
    "    gen_samples = np.load('C:/Users/Albert/Desktop/CMPE_295/Code/FC_VAEAllFiveFamilies_.npy')\n",
    "            \n",
    "\n",
    "    ### Start Binary Search ###\n",
    "    linear_end_flag = 0\n",
    "    binary_start_flag = 0\n",
    "    binary_end_flag = 0\n",
    "    binary_continue_flag = 0\n",
    "    mid = 0\n",
    "    while binary_end_flag == 0:\n",
    "        low = 0\n",
    "        count = 0\n",
    "  \n",
    "        if present_num_sample > 0 and binary_start_flag == 0:\n",
    "            high = present_num_sample\n",
    "            binary_start_flag = 1\n",
    "        elif binary_continue_flag == 1:\n",
    "            high = mid\n",
    "        else:\n",
    "            high = len(real_data)\n",
    "\n",
    "        saved_high = high\n",
    "        while low <= high:\n",
    "            mid = (high + low) // 2\n",
    "\n",
    "            if mid < 20: # Make sure num_samples do not go under 5 because of k-folds = 5\n",
    "                binary_end_flag == 1\n",
    "                mid = 20\n",
    "                break\n",
    "\n",
    "            num_samples = mid\n",
    "            #print('Generated Samples: %s      Acutal Malware Files Used: %s' % (num_samples,num_samples))\n",
    "\n",
    "            idx = np.random.randint(0, real_data.shape[0], num_samples)\n",
    "            real_samples = real_data[idx]\n",
    "\n",
    "            #### Generate Samples ####\n",
    "            fake_samples = gen_samples[idx]\n",
    "\n",
    "            #print(fake_samples.shape)\n",
    "\n",
    "            #### Define Training and Test Datasets ####\n",
    "            X = np.concatenate([real_samples, fake_samples])\n",
    "            y= [1]*num_samples + [0]*num_samples\n",
    "            X = np.array(X,dtype=object)\n",
    "            y = np.array(y,dtype='int64')\n",
    "\n",
    "            if function.__name__ in deep:\n",
    "                accuracy, precision, recall = function(X,y,real_malware,target_names,max_sequence_length, embedding_vector_length, num_unique)\n",
    "            else:\n",
    "                accuracy, precision, recall = function(X,y,real_malware,target_names,max_sequence_length)\n",
    "            if accuracy < 0.95:\n",
    "                low = mid + 1\n",
    "\n",
    "            elif accuracy > 0.95:\n",
    "                high = mid -1\n",
    "                count += 1\n",
    "\n",
    "\n",
    "        if count <= 1: # if binary search does not find a num_samples that classifys with .95 accuracy, return highest value\n",
    "            mid = saved_high\n",
    "            binary_end_flag = 1\n",
    "            if binary_continue_flag == 0:\n",
    "                linear_end_flag = 1 #dont do linear search if binary search doesnt find any num_sample values to get to .95\n",
    "\n",
    "\n",
    "\n",
    "        if binary_end_flag == 0:\n",
    "            binary_continue_flag = 1\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%H:%M:%S\")\n",
    "            print('%s: Binary search in progress, Accuracy = %0.2f,  Num_Samples = %i' % (current_time, accuracy, mid))\n",
    "\n",
    "\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print('%s: Binary search result for %s: %i samples needed for .95 accuracy' % (current_time, function.__name__, mid))\n",
    "\n",
    "    ### Start Jump Search ###\n",
    "    if linear_end_flag == 1:\n",
    "        num_samples = mid\n",
    "    else:\n",
    "        num_samples = mid - 1\n",
    "\n",
    "    final_loop = 0\n",
    "    decrement = 10\n",
    "    while linear_end_flag == 0:\n",
    "        for loop_num in range(num_tries):\n",
    "\n",
    "            #print('Generated Samples: %s      Acutal Malware Files Used: %s' % (num_samples,num_samples))\n",
    "\n",
    "            idx = np.random.randint(0, real_data.shape[0], num_samples)\n",
    "            real_samples = real_data[idx]\n",
    "\n",
    "            #### Generate Samples ####\n",
    "            fake_samples = gen_samples[idx]\n",
    "\n",
    "            #print(fake_samples.shape)\n",
    "\n",
    "            #### Define Training and Test Datasets ####\n",
    "            X = np.concatenate([real_samples, fake_samples])\n",
    "            y= [1]*num_samples + [0]*num_samples\n",
    "            X = np.array(X,dtype=object)\n",
    "            y = np.array(y,dtype='int64')\n",
    "\n",
    "            if function.__name__ in deep:\n",
    "                accuracy, precision, recall = function(X,y,real_malware,target_names,max_sequence_length, embedding_vector_length, num_unique)\n",
    "            else:\n",
    "                accuracy, precision, recall = function(X,y,real_malware,target_names,max_sequence_length)\n",
    "\n",
    "            if num_samples <= 10:\n",
    "                linear_end_flag = 1\n",
    "                break\n",
    "            \n",
    "            if accuracy > 0.95:\n",
    "                if final_loop == 1:\n",
    "                    linear_end_flag = 1\n",
    "                    #### Display All Classification Results ####\n",
    "                    now = datetime.now()\n",
    "                    current_time = now.strftime(\"%H:%M:%S\")\n",
    "                    print('%s: Linear search in progress, Accuracy = %0.2f,  Num_Samples = %i,  Number_of_Tries = %i' % (current_time, accuracy, num_samples, (loop_num+1)))\n",
    "                    print('%s: Linear search result for %s is complete: %i samples needed for .95 accuracy' % (current_time, function.__name__, num_samples))\n",
    "                    break\n",
    "                elif num_samples <= 20 and linear_end_flag == 0:\n",
    "                    num_samples -= 1\n",
    "                    now = datetime.now()\n",
    "                    current_time = now.strftime(\"%H:%M:%S\")\n",
    "                    print('%s: Linear search in progress, Accuracy = %0.2f,  Num_Samples = %i,  Number_of_Tries = %i' % (current_time, accuracy, num_samples, (loop_num+1)))\n",
    "                else:\n",
    "                    num_samples -= decrement\n",
    "                    now = datetime.now()\n",
    "                    current_time = now.strftime(\"%H:%M:%S\")\n",
    "                    print('%s: Linear search in progress, Accuracy = %0.2f,  Num_Samples = %i,  Number_of_Tries = %i' % (current_time, accuracy, num_samples, (loop_num+1)))\n",
    "                break\n",
    "            if loop_num == (num_tries - 1):\n",
    "                final_loop = 1\n",
    "                num_samples += 1\n",
    "                now = datetime.now()\n",
    "                current_time = now.strftime(\"%H:%M:%S\")\n",
    "                print('%s: Linear search in progress, Accuracy = %0.2f,  Num_Samples = %i,  Number_of_Tries = %i' % (current_time, accuracy, num_samples, (loop_num+1)))\n",
    "                                   \n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print('%s: Linear search result for %s is complete: %i samples needed for .95 accuracy' % (current_time, function.__name__, num_samples))\n",
    "\n",
    "    return num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples for AllFiveFamilies: 12271\n",
      "Mappings in JSON file: 40\n",
      "Total valid samples for AllFiveFamilies: 11335\n",
      "01:02:10: Binary search in progress, Accuracy = 0.95,  Num_Samples = 132\n",
      "01:02:10: Binary search in progress, Accuracy = 0.97,  Num_Samples = 20\n",
      "01:02:10: Binary search result for support_vector_machine: 20 samples needed for .95 accuracy\n",
      "01:02:10: Linear search in progress, Accuracy = 0.97,  Num_Samples = 18,  Number_of_Tries = 1\n",
      "01:02:10: Linear search in progress, Accuracy = 1.00,  Num_Samples = 17,  Number_of_Tries = 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albert\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:02:10: Linear search in progress, Accuracy = 0.97,  Num_Samples = 16,  Number_of_Tries = 4\n",
      "01:02:10: Linear search in progress, Accuracy = 0.97,  Num_Samples = 15,  Number_of_Tries = 1\n",
      "01:02:10: Linear search in progress, Accuracy = 0.97,  Num_Samples = 14,  Number_of_Tries = 4\n",
      "01:02:10: Linear search in progress, Accuracy = 0.96,  Num_Samples = 13,  Number_of_Tries = 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albert\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:02:10: Linear search in progress, Accuracy = 1.00,  Num_Samples = 12,  Number_of_Tries = 3\n",
      "01:02:10: Linear search in progress, Accuracy = 0.96,  Num_Samples = 11,  Number_of_Tries = 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albert\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Albert\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Albert\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Albert\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Albert\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Albert\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Albert\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Albert\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:02:11: Linear search in progress, Accuracy = 0.96,  Num_Samples = 10,  Number_of_Tries = 3\n",
      "01:02:11: Linear search result for support_vector_machine: 10 samples needed for .95 accuracy\n",
      "Total samples for AllFiveFamilies: 12271\n",
      "Mappings in JSON file: 40\n",
      "Total valid samples for AllFiveFamilies: 11335\n",
      "01:02:54: Binary search in progress, Accuracy = 0.93,  Num_Samples = 50\n",
      "01:02:56: Binary search result for random_forest: 50 samples needed for .95 accuracy\n",
      "01:02:57: Linear search in progress, Accuracy = 0.98,  Num_Samples = 39,  Number_of_Tries = 4\n",
      "01:03:01: Linear search in progress, Accuracy = 0.96,  Num_Samples = 29,  Number_of_Tries = 10\n",
      "01:03:08: Linear search in progress, Accuracy = 0.81,  Num_Samples = 30,  Number_of_Tries = 20\n",
      "01:03:16: Linear search in progress, Accuracy = 0.87,  Num_Samples = 31,  Number_of_Tries = 20\n",
      "01:03:20: Linear search result for random_forest: 31 samples needed for .95 accuracy\n",
      "Total samples for AllFiveFamilies: 12271\n",
      "Mappings in JSON file: 40\n",
      "Total valid samples for AllFiveFamilies: 11335\n",
      "01:06:32: Binary search result for k_nearest_neighbors: 11335 samples needed for .95 accuracy\n",
      "01:06:32: Linear search result for k_nearest_neighbors: 11335 samples needed for .95 accuracy\n",
      "Total samples for AllFiveFamilies: 12271\n",
      "Mappings in JSON file: 40\n",
      "Total valid samples for AllFiveFamilies: 11335\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000027153AC4040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002714F57A700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "01:10:41: Binary search in progress, Accuracy = 0.96,  Num_Samples = 89\n",
      "01:13:52: Binary search in progress, Accuracy = 0.96,  Num_Samples = 59\n",
      "01:17:13: Binary search result for lstm_kfold: 59 samples needed for .95 accuracy\n",
      "01:18:15: Linear search in progress, Accuracy = 0.97,  Num_Samples = 48,  Number_of_Tries = 2\n",
      "01:19:57: Linear search in progress, Accuracy = 0.97,  Num_Samples = 38,  Number_of_Tries = 3\n",
      "01:21:07: Linear search in progress, Accuracy = 0.97,  Num_Samples = 28,  Number_of_Tries = 2\n",
      "01:23:03: Linear search in progress, Accuracy = 0.96,  Num_Samples = 18,  Number_of_Tries = 4\n",
      "01:25:15: Linear search in progress, Accuracy = 0.97,  Num_Samples = 17,  Number_of_Tries = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albert\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:29:31: Linear search in progress, Accuracy = 0.97,  Num_Samples = 16,  Number_of_Tries = 8\n",
      "01:30:36: Linear search in progress, Accuracy = 0.97,  Num_Samples = 15,  Number_of_Tries = 2\n",
      "01:34:20: Linear search in progress, Accuracy = 0.97,  Num_Samples = 14,  Number_of_Tries = 8\n",
      "01:36:24: Linear search in progress, Accuracy = 0.97,  Num_Samples = 13,  Number_of_Tries = 4\n",
      "01:45:11: Linear search in progress, Accuracy = 1.00,  Num_Samples = 12,  Number_of_Tries = 17\n",
      "01:46:45: Linear search in progress, Accuracy = 0.96,  Num_Samples = 11,  Number_of_Tries = 3\n",
      "01:47:46: Linear search in progress, Accuracy = 1.00,  Num_Samples = 10,  Number_of_Tries = 2\n",
      "01:48:29: Linear search result for lstm_kfold: 10 samples needed for .95 accuracy\n",
      "Total samples for AllFiveFamilies: 12271\n",
      "Mappings in JSON file: 40\n",
      "Total valid samples for AllFiveFamilies: 11335\n",
      "02:41:19: Binary search in progress, Accuracy = 0.97,  Num_Samples = 154\n",
      "02:43:13: Binary search in progress, Accuracy = 0.99,  Num_Samples = 20\n",
      "02:43:13: Binary search result for bi_lstm_kfold: 20 samples needed for .95 accuracy\n",
      "02:45:35: Linear search in progress, Accuracy = 0.97,  Num_Samples = 18,  Number_of_Tries = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albert\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:50:29: Linear search in progress, Accuracy = 1.00,  Num_Samples = 17,  Number_of_Tries = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albert\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:56:34: Linear search in progress, Accuracy = 0.97,  Num_Samples = 16,  Number_of_Tries = 7\n",
      "02:57:23: Linear search in progress, Accuracy = 0.97,  Num_Samples = 15,  Number_of_Tries = 1\n",
      "03:06:13: Linear search in progress, Accuracy = 0.97,  Num_Samples = 14,  Number_of_Tries = 11\n",
      "03:20:48: Linear search in progress, Accuracy = 0.97,  Num_Samples = 13,  Number_of_Tries = 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albert\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:23:25: Linear search in progress, Accuracy = 1.00,  Num_Samples = 12,  Number_of_Tries = 3\n",
      "03:24:16: Linear search in progress, Accuracy = 0.96,  Num_Samples = 11,  Number_of_Tries = 1\n",
      "03:27:37: Linear search in progress, Accuracy = 0.96,  Num_Samples = 10,  Number_of_Tries = 4\n",
      "03:28:38: Linear search result for bi_lstm_kfold: 10 samples needed for .95 accuracy\n",
      "Total samples for AllFiveFamilies: 12271\n",
      "Mappings in JSON file: 40\n",
      "Total valid samples for AllFiveFamilies: 11335\n",
      "03:50:53: Binary search in progress, Accuracy = 0.91,  Num_Samples = 22\n",
      "03:50:53: Binary search result for cnn_lstm_kfold: 22 samples needed for .95 accuracy\n",
      "03:51:22: Linear search in progress, Accuracy = 0.95,  Num_Samples = 11,  Number_of_Tries = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albert\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:53:12: Linear search in progress, Accuracy = 0.96,  Num_Samples = 10,  Number_of_Tries = 4\n",
      "03:53:45: Linear search result for cnn_lstm_kfold: 10 samples needed for .95 accuracy\n",
      "AllFiveFamilies\n",
      "-------------------------------------------------------------\n",
      "SVM Epochs:                      10\n",
      "Random Forest Epochs:            31\n",
      "k-Nearest Neighbor Epochs:       11335\n",
      "Standard LSTM Epochs:            10\n",
      "Bidirectional LSTM Epochs:       10\n",
      "CNN LSTM Epochs:                 10\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#malware_familes = ['AllFiveFamilies','OnLineGames', 'Renos', 'VBInject', 'WinWebSec', 'Zbot']\n",
    "malware_familes = ['AllFiveFamilies']\n",
    "\n",
    "for real_malware in malware_familes:\n",
    "    svm_num_samples  = combined_search(real_malware, support_vector_machine) \n",
    "    rf_num_samples  = combined_search(real_malware, random_forest) \n",
    "    knn_num_samples  = combined_search(real_malware, k_nearest_neighbors) \n",
    "\n",
    "    lstm_num_samples  = combined_search(real_malware, lstm_kfold, 100)\n",
    "    bi_lstm_num_samples  = combined_search(real_malware, bi_lstm_kfold)\n",
    "    cnn_lstm_num_samples  = combined_search(real_malware, cnn_lstm_kfold)\n",
    "    \n",
    "    print(real_malware)\n",
    "    print('-------------------------------------------------------------')\n",
    "    print(\"SVM Epochs:                     \", svm_num_samples) #10\n",
    "    print(\"Random Forest Epochs:           \", rf_num_samples) #31\n",
    "    print(\"k-Nearest Neighbor Epochs:      \", knn_num_samples) #11335\n",
    "\n",
    "    print(\"Standard LSTM Epochs:           \", lstm_num_samples) #10\n",
    "    print(\"Bidirectional LSTM Epochs:      \", bi_lstm_num_samples) #10\n",
    "    print(\"CNN LSTM Epochs:                \", cnn_lstm_num_samples) #10\n",
    "    print('-------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
