{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malware Opcode Classification \n",
    "\n",
    "Authored by David Luong\n",
    "\n",
    "Reference: https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt # for plotting model loss\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "#Import svm model\n",
    "from sklearn import svm\n",
    "#Import random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "#Import knn model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Final evaluation of the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(7)\n",
    "np.random.seed(7)\n",
    "tf.keras.utils.set_random_seed(7)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# Assign main directory to a variable\n",
    "main_dir=os.path.dirname(sys.path[0])\n",
    "\n",
    "import data\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(X, y, real_malware, target_names,max_sequence_length, embedding_vector_length, num_unique):\n",
    "    classifier_name = 'LSTM'\n",
    "    #print('******%s******' % classifier_name)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "    clf = Sequential()\n",
    "    clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "    clf.add(LSTM(100))\n",
    "    clf.add(Dense(1, activation='sigmoid'))\n",
    "    clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])   \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "    clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "    scores = clf.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy = scores[1]\n",
    "    y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall= recall_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "    return accuracy, precision, recall, class_report\n",
    "\n",
    "def lstm_kfold(X, y, real_malware, target_names,max_sequence_length, embedding_vector_length, num_unique):\n",
    "    classifier_name = 'LSTM'\n",
    "    #print('******%s******' % classifier_name)\n",
    "    k = 5\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    best = 0.\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=18245)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "    \n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # build LSTM model\n",
    "        clf = Sequential()\n",
    "        clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "        clf.add(LSTM(100))\n",
    "        clf.add(Dense(1, activation='sigmoid'))\n",
    "        clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])   \n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "        clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "        scores = clf.evaluate(X_test, y_test, verbose=0)\n",
    "        acc = scores[1]\n",
    "        accuracy.append(acc)\n",
    "        if acc>best:\n",
    "            best = acc\n",
    "            best_train, best_test = train_index, test_index\n",
    "            \n",
    "        y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        \n",
    "    # print('\\n%s accuracy: ' % classifier_name, accuracy)\n",
    "    # print('%s precision: ' % classifier_name, precision)\n",
    "    # print('%s recall: ' % classifier_name, recall)\n",
    "    \n",
    "    # print('\\nAvg %s accuracy: %0.2f'% (classifier_name, np.mean(np.array(accuracy))))\n",
    "    # print('Avg %s precision: %0.2f'% (classifier_name, np.mean(np.array(precision))))\n",
    "    # print('Avg %s recall: %0.2f\\n'% (classifier_name ,np.mean(np.array(recall))))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[best_train], X[best_test], y[best_train], y[best_test]\n",
    "    clf = Sequential()\n",
    "    clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "    clf.add(LSTM(100))\n",
    "    clf.add(Dense(1, activation='sigmoid'))\n",
    "    clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])   \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "    clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "    y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "\n",
    "    return np.mean(np.array(accuracy)), np.mean(np.array(precision)), np.mean(np.array(recall)), class_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Bidirectional LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_lstm(X, y, real_malware, target_names,max_sequence_length, embedding_vector_length, num_unique):\n",
    "    classifier_name = 'Bidirectional_LSTM'\n",
    "    #print('******%s******' % classifier_name)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "    clf = Sequential()\n",
    "    clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "    #clf.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "    clf.add(Bidirectional(LSTM(100, dropout=0.2)))\n",
    "    clf.add(Dense(1, activation='sigmoid'))\n",
    "    clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "    clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "    scores = clf.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy = scores[1]\n",
    "    y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall= recall_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "\n",
    "    return accuracy, precision, recall, class_report\n",
    "\n",
    "def bi_lstm_kfold(X, y, real_malware, target_names,max_sequence_length, embedding_vector_length, num_unique):\n",
    "    classifier_name = 'Bidirectional_LSTM'\n",
    "    #print('******%s******' % classifier_name)\n",
    "    k = 5\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    best = 0.\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=18245)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "    \n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # build LSTM model\n",
    "        clf = Sequential()\n",
    "        clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "        #clf.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "        clf.add(Bidirectional(LSTM(100, dropout=0.2)))\n",
    "        clf.add(Dense(1, activation='sigmoid'))\n",
    "        clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "        clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "        scores = clf.evaluate(X_test, y_test, verbose=0)\n",
    "        acc = scores[1]\n",
    "        accuracy.append(acc)\n",
    "        if acc>best:\n",
    "            best = acc\n",
    "            best_train, best_test = train_index, test_index\n",
    "            \n",
    "        y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        \n",
    "    # print('\\n%s accuracy: ' % classifier_name, accuracy)\n",
    "    # print('%s precision: ' % classifier_name, precision)\n",
    "    # print('%s recall: ' % classifier_name, recall)\n",
    "    \n",
    "    # print('\\nAvg %s accuracy: %0.2f'% (classifier_name, np.mean(np.array(accuracy))))\n",
    "    # print('Avg %s precision: %0.2f'% (classifier_name, np.mean(np.array(precision))))\n",
    "    # print('Avg %s recall: %0.2f\\n'% (classifier_name ,np.mean(np.array(recall))))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[best_train], X[best_test], y[best_train], y[best_test]\n",
    "    clf = Sequential()\n",
    "    clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "    #clf.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "    clf.add(Bidirectional(LSTM(100, dropout=0.2)))\n",
    "    clf.add(Dense(1, activation='sigmoid'))\n",
    "    clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "    clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "    y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "\n",
    "    return np.mean(np.array(accuracy)), np.mean(np.array(precision)), np.mean(np.array(recall)), class_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define CNN LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_lstm(X, y, real_malware, target_names,max_sequence_length, embedding_vector_length, num_unique):\n",
    "    classifier_name = 'CNN_LSTM'\n",
    "    #print('******%s******' % classifier_name)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "    \n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "    clf = Sequential()\n",
    "    clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "    clf.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "    clf.add(MaxPooling1D(pool_size=2))\n",
    "    clf.add(LSTM(100))\n",
    "    clf.add(Dense(1, activation='sigmoid'))\n",
    "    clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "    clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "    scores = clf.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy = scores[1]\n",
    "    y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall= recall_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "\n",
    "    return accuracy, precision, recall, class_report\n",
    "\n",
    "def cnn_lstm_kfold(X, y, real_malware, target_names,max_sequence_length, embedding_vector_length, num_unique):\n",
    "    classifier_name = 'CNN_LSTM'\n",
    "    #print('******%s******' % classifier_name)\n",
    "    k = 5\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    best = 0.\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=18245)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "    \n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # build LSTM model\n",
    "        clf = Sequential()\n",
    "        clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "        clf.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "        clf.add(MaxPooling1D(pool_size=2))\n",
    "        clf.add(LSTM(100))\n",
    "        clf.add(Dense(1, activation='sigmoid'))\n",
    "        clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "        clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "        scores = clf.evaluate(X_test, y_test, verbose=0)\n",
    "        acc = scores[1]\n",
    "        accuracy.append(acc)\n",
    "        if acc>best:\n",
    "            best = acc\n",
    "            best_train, best_test = train_index, test_index\n",
    "            \n",
    "        y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        \n",
    "    # print('\\n%s accuracy: ' % classifier_name, accuracy)\n",
    "    # print('%s precision: ' % classifier_name, precision)\n",
    "    # print('%s recall: ' % classifier_name, recall)\n",
    "    \n",
    "    # print('\\nAvg %s accuracy: %0.2f'% (classifier_name, np.mean(np.array(accuracy))))\n",
    "    # print('Avg %s precision: %0.2f'% (classifier_name, np.mean(np.array(precision))))\n",
    "    # print('Avg %s recall: %0.2f\\n'% (classifier_name ,np.mean(np.array(recall))))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[best_train], X[best_test], y[best_train], y[best_test]\n",
    "    clf = Sequential()\n",
    "    clf.add(Embedding(num_unique, embedding_vector_length, input_length=max_sequence_length))\n",
    "    clf.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "    clf.add(MaxPooling1D(pool_size=2))\n",
    "    clf.add(LSTM(100))\n",
    "    clf.add(Dense(1, activation='sigmoid'))\n",
    "    clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta = 0.01, patience=10, restore_best_weights=True)\n",
    "    clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[callback], verbose=0)\n",
    "    y_pred = np.round(clf.predict(X_test, verbose=0))\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "\n",
    "    return np.mean(np.array(accuracy)), np.mean(np.array(precision)), np.mean(np.array(recall)), class_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define SVM Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vector_machine(X, y, real_malware, target_names,max_sequence_length):\n",
    "    classifier_name = 'Support Vector Machines'\n",
    "    #print('******%s******' % classifier_name)\n",
    "    k = 5\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    best = 0.\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf = svm.SVC(C=5, kernel='rbf')\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc = clf.score(X_test, y_test)\n",
    "        accuracy.append(acc)\n",
    "        if acc>best:\n",
    "            best = acc\n",
    "            best_train, best_test = train_index, test_index\n",
    "            \n",
    "        y_pred = clf.predict(X_test)\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        \n",
    "    # print('\\n%s accuracy: ' % classifier_name, accuracy)\n",
    "    # print('%s precision: ' % classifier_name, precision)\n",
    "    # print('%s recall: ' % classifier_name, recall)\n",
    "    \n",
    "    # print('\\nAvg %s accuracy: %0.2f'% (classifier_name, np.mean(np.array(accuracy))))\n",
    "    # print('Avg %s precision: %0.2f'% (classifier_name, np.mean(np.array(precision))))\n",
    "    # print('Avg %s recall: %0.2f\\n'% (classifier_name ,np.mean(np.array(recall))))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[best_train], X[best_test], y[best_train], y[best_test]\n",
    "    clf = svm.SVC(C=5, kernel='rbf')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "\n",
    "    return np.mean(np.array(accuracy)), np.mean(np.array(precision)), np.mean(np.array(recall)), class_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X, y, real_malware, target_names,max_sequence_length):\n",
    "    classifier_name = 'Random Forest'\n",
    "    #print('******%s******' % classifier_name)\n",
    "    k = 5\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    best = 0.\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=6357)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf = RandomForestClassifier(n_estimators=50, max_depth=5)\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc = clf.score(X_test, y_test)\n",
    "        accuracy.append(acc)\n",
    "        if acc>best:\n",
    "            best = acc\n",
    "            best_train, best_test = train_index, test_index\n",
    "            \n",
    "        y_pred = clf.predict(X_test)\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        \n",
    "    # print('\\n%s accuracy: ' % classifier_name, accuracy)\n",
    "    # print('%s precision: ' % classifier_name, precision)\n",
    "    # print('%s recall: ' % classifier_name, recall)\n",
    "    \n",
    "    # print('\\nAvg %s accuracy: %0.2f'% (classifier_name, np.mean(np.array(accuracy))))\n",
    "    # print('Avg %s precision: %0.2f'% (classifier_name, np.mean(np.array(precision))))\n",
    "    # print('Avg %s recall: %0.2f\\n'% (classifier_name ,np.mean(np.array(recall))))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[best_train], X[best_test], y[best_train], y[best_test]\n",
    "    clf = RandomForestClassifier(n_estimators=50, max_depth=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "\n",
    "    return np.mean(np.array(accuracy)), np.mean(np.array(precision)), np.mean(np.array(recall)), class_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define k-Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbors(X, y, real_malware, target_names,max_sequence_length):\n",
    "    classifier_name = 'K-Nearest Neighbors'\n",
    "    #print('******%s******' % classifier_name)\n",
    "    k = 5\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    best = 0.\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=18245)\n",
    "\n",
    "    # truncate and pad input sequences\n",
    "    X = sequence.pad_sequences(X, maxlen=max_sequence_length)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf = KNeighborsClassifier(n_neighbors=1, p=2)\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc = clf.score(X_test, y_test)\n",
    "        accuracy.append(acc)\n",
    "        if acc>best:\n",
    "            best = acc\n",
    "            best_train, best_test = train_index, test_index\n",
    "            \n",
    "        y_pred = clf.predict(X_test)\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        \n",
    "    # print('\\n%s accuracy: ' % classifier_name, accuracy)\n",
    "    # print('%s precision: ' % classifier_name, precision)\n",
    "    # print('%s recall: ' % classifier_name, recall)\n",
    "    \n",
    "    # print('\\nAvg %s accuracy: %0.2f'% (classifier_name, np.mean(np.array(accuracy))))\n",
    "    # print('Avg %s precision: %0.2f'% (classifier_name, np.mean(np.array(precision))))\n",
    "    # print('Avg %s recall: %0.2f\\n'% (classifier_name ,np.mean(np.array(recall))))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[best_train], X[best_test], y[best_train], y[best_test]\n",
    "    clf = KNeighborsClassifier(n_neighbors=1, p=2)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(4,4))\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=np.array(['real', 'fake']), cmap=plt.cm.Blues, ax=ax)\n",
    "    #ax.set_title('%s Confusion Matrix \\n using %s'%(real_malware,classifier_name))\n",
    "    #plt.show()\n",
    "    \n",
    "    class_report = classification_report(y_test, y_pred, target_names=target_names) \n",
    "\n",
    "    return np.mean(np.array(accuracy)), np.mean(np.array(precision)), np.mean(np.array(recall)), class_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_search(real_malware, function):\n",
    "    #### Define Run Settings ####\n",
    "    tf.random.set_seed(7)\n",
    "    np.random.seed(7)\n",
    "    tf.keras.utils.set_random_seed(7)\n",
    "\n",
    "    max_sequence_length = 600\n",
    "    use_deep_classifiers = 1 # 1+ = use, 0 do not use \n",
    "    target_names = ['Real', 'Fake']\n",
    "    embedding_vector_length = 32\n",
    "    num_tries = 20\n",
    "    save_epoch = []\n",
    "    latent_dim = 100\n",
    "    architecture = 'WGANGP'\n",
    "    deep = ['cnn_lstm_kfold','bi_lstm_kfold','lstm_kfold','cnn_lstm','bi_lstm','lstm']\n",
    "\n",
    "\n",
    "    if real_malware == 'AllFiveFamilies':\n",
    "        epoch_num = 1000\n",
    "    else:\n",
    "        epoch_num = 10000\n",
    "    \n",
    "\n",
    "    #### Load Real Samples ####\n",
    "    data_obj = data.DATA(real_malware, 600)\n",
    "    real_data, num_unique = data_obj.load_data(True)\n",
    "    generator = load_model('C:/Users/Albert/Desktop/CMPE_295/%s_Results/Models_test/%s/%s_generator_%d.hdf5' % (architecture, real_malware, real_malware, epoch_num), compile=False, custom_objects={'LeakyReLU': LeakyReLU})\n",
    "\n",
    "    ### Start Binary Search ###\n",
    "    low = 0\n",
    "    mid = 0\n",
    "    count = 0\n",
    "    high = len(real_data) - 1\n",
    "    saved_high = high\n",
    "\n",
    "    while low <= high:\n",
    "        mid = (high + low) // 2\n",
    "\n",
    "        if mid < 5: # Make sure num_samples do not go under 5 because of k-folds = 5\n",
    "            mid = 5\n",
    "\n",
    "        num_samples = mid\n",
    "        #print('Generated Samples: %s      Acutal Malware Files Used: %s' % (num_samples,num_samples))\n",
    "\n",
    "        idx = np.random.randint(0, real_data.shape[0], num_samples)\n",
    "        real_samples = real_data[idx]\n",
    "\n",
    "        #### Generate Samples ####\n",
    "        \n",
    "        noise = np.random.normal(0, 1, (num_samples, latent_dim))\n",
    "        gen_samples = generator.predict(noise, verbose=0)\n",
    "        gen_samples = (gen_samples + 1) * num_unique/2\n",
    "        gen_samples = np.rint(gen_samples)\n",
    "        gen_samples = gen_samples.astype(int)\n",
    "        gen_samples = np.reshape(gen_samples, (num_samples, 600))\n",
    "        #print(gen_samples.shape)\n",
    "\n",
    "        #### Define Training and Test Datasets ####\n",
    "        X = np.concatenate([real_samples, gen_samples])\n",
    "        y= [1]*num_samples + [0]*num_samples\n",
    "        X = np.array(X,dtype=object)\n",
    "        y = np.array(y,dtype='int64')\n",
    "\n",
    "        if function.__name__ in deep:\n",
    "            accuracy, precision, recall, svm_results = function(X,y,real_malware,target_names,max_sequence_length, embedding_vector_length, num_unique)\n",
    "        else:\n",
    "            accuracy, precision, recall, svm_results = function(X,y,real_malware,target_names,max_sequence_length)\n",
    "        if accuracy < 0.95:\n",
    "            low = mid + 1\n",
    "\n",
    "        elif accuracy > 0.95:\n",
    "            high = mid -1\n",
    "            count += 1\n",
    "            \n",
    "    if count <= 1: # if binary search does not find a num_samples that classifys with .95 accuracy, return highest value\n",
    "        mid = saved_high\n",
    "\n",
    "    #for loop_num in range(num_tries):\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    print('%s: Binary search result for %s: %i samples needed for .95 accuracy' % (current_time, function.__name__, mid))\n",
    "\n",
    "    ### Start Linear Search ###\n",
    "    num_samples = mid - 1\n",
    "    end_flag = 0\n",
    "    while end_flag == 0:\n",
    "        for loop_num in range(num_tries):\n",
    "\n",
    "            #print('Generated Samples: %s      Acutal Malware Files Used: %s' % (num_samples,num_samples))\n",
    "\n",
    "            idx = np.random.randint(0, real_data.shape[0], num_samples)\n",
    "            real_samples = real_data[idx]\n",
    "\n",
    "            #### Generate Samples ####\n",
    "            \n",
    "            noise = np.random.normal(0, 1, (num_samples, latent_dim))\n",
    "            gen_samples = generator.predict(noise, verbose=0)\n",
    "            gen_samples = (gen_samples + 1) * num_unique/2\n",
    "            gen_samples = np.rint(gen_samples)\n",
    "            gen_samples = gen_samples.astype(int)\n",
    "            gen_samples = np.reshape(gen_samples, (num_samples, 600))\n",
    "            #print(gen_samples.shape)\n",
    "\n",
    "            #### Define Training and Test Datasets ####\n",
    "            X = np.concatenate([real_samples, gen_samples])\n",
    "            y= [1]*num_samples + [0]*num_samples\n",
    "            X = np.array(X,dtype=object)\n",
    "            y = np.array(y,dtype='int64')\n",
    "\n",
    "            if function.__name__ in deep:\n",
    "                accuracy, precision, recall, svm_results = function(X,y,real_malware,target_names,max_sequence_length, embedding_vector_length, num_unique)\n",
    "            else:\n",
    "                accuracy, precision, recall, svm_results = function(X,y,real_malware,target_names,max_sequence_length)\n",
    "            if accuracy > 0.95:\n",
    "                num_samples -= 1\n",
    "                break\n",
    "            if loop_num == (num_tries - 1):\n",
    "                end_flag = 1\n",
    "                num_samples += 1\n",
    "            if num_samples == 5: # Make sure num_samples do not go under 5 because of k-folds = 5\n",
    "                end_flag = 1\n",
    "        if (mid  - num_samples) % 10 == 0:\n",
    "            print('%s: Linear search in progress, Accuracy = %0.2f,  Num_Samples = %i' % (current_time, accuracy, num_samples))\n",
    "            \n",
    "\n",
    "\n",
    "    #### Display All Classification Results ####\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    print('%s: Linear search result for %s: %i samples needed for .95 accuracy' % (current_time, function.__name__, num_samples))\n",
    "    return num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#malware_familes = ['AllFiveFamilies','OnLineGames', 'Renos', 'VBInject', 'WinWebSec', 'Zbot']\n",
    "malware_familes = ['AllFiveFamilies']\n",
    "\n",
    "for real_malware in malware_familes:\n",
    "    svm_num_samples  = combined_search(real_malware, support_vector_machine)\n",
    "    rf_num_samples  = combined_search(real_malware, random_forest)\n",
    "    knn_num_samples  = combined_search(real_malware, k_nearest_neighbors)\n",
    "\n",
    "    lstm_num_samples  = combined_search(real_malware, lstm_kfold)\n",
    "    bi_lstm_num_samples  = combined_search(real_malware, bi_lstm_kfold)\n",
    "    cnn_lstm_num_samples  = combined_search(real_malware, cnn_lstm_kfold)\n",
    "    \n",
    "    print(real_malware)\n",
    "    print('-------------------------------------------------------------')\n",
    "    print(\"SVM Epochs:                     \", svm_num_samples)\n",
    "    print(\"Random Forest Epochs:           \", rf_num_samples)\n",
    "    print(\"k-Nearest Neighbor Epochs:      \", knn_num_samples)\n",
    "\n",
    "    print(\"Standard LSTM Epochs:           \", lstm_num_samples)\n",
    "    print(\"Bidirectional LSTM Epochs:      \", bi_lstm_num_samples)\n",
    "    print(\"CNN LSTM Epochs:                \", cnn_lstm_num_samples)\n",
    "    print('-------------------------------------------------------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Real and Fake Malware Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = sequence.pad_sequences(X, maxlen=600, dtype='int32',\n",
    "    padding='pre', truncating='pre', value=0.)\n",
    "\n",
    "print('Real Malware - ' + real_malware)\n",
    "plt.matshow(np.array(tmp[4]).reshape(20,30))\n",
    "#plt.show()\n",
    "\n",
    "print('Fake Malware - ' + real_malware)\n",
    "plt.matshow(np.array(tmp[199]).reshape(20,30))\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
